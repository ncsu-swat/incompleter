# LExecutor: DO NOT INSTRUMENT

#Source: https://stackoverflow.com/questions/70119607/nlp-tokenize-typeerror-expected-string-or-bytes-like-object
from lexecutor.Runtime import _n_
from lexecutor.Runtime import _a_
from lexecutor.Runtime import _c_
from lexecutor.Runtime import _l_
_c_(539223, _n_(539219, "print", lambda: print), _c_(539222, _n_(539220, "word_tokenize", lambda: word_tokenize), _n_(539221, "data", lambda: data)))
_l_(539224)