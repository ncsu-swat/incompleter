{\rtf1\ansi\ansicpg1252\cocoartf2708
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red193\green193\blue193;}
{\*\expandedcolortbl;;\cssrgb\c80000\c80000\c80000;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Incompleter\
47 (old) 49 (new)\
48\
47\
51\
49\
37 (old) 46 (new)\
Avg: 49\
\
\
LExecutor\
49\
47\
43\
55\
33\
36\
Avg: 44\
\
\
\
\
\
1. Checked the snippets where none of the techniques worked.\
2. Checked the last error that LExectuor had produced in these cases.\
3. 10% were TypeError: 'DummyObject' is not iterable/subscriptable/callable\
4. 5% were NameError\
5. 5% were FileNotFoundError\
\
\
Average lengths of snippets for LExecutor:\
(Total/Fail/Success)\
Chunk1: (1252 || 1386 || 1061)\
Chunk2: (1501 || 1510 || 1197)\
Chunk3: (1531 || 1614 || 1200)\
Chunk4: (1773 || 2172 || 1349)\
Chunk5: (1596 || 1653 || 1225)\
Chunk6: (1674 || 1786 || 1237)\
\
Average lengths of snippets for Incompleter:\
(Total/Fail/Success)\
Chunk1: (1252 || 1521 || 953)\
Chunk2: (1501 || 1706 || 1259)\
Chunk3: (1531 || 1892 || 1061)\
Chunk4: (1773 || 2045 || 1480)\
Chunk5: (1596 || 1833 || 1293)\
Chunk6: (1674 || 1873 || 1333)\
\
\
\
Preprocessing:\
All iterables/subscriptables --> TBDs for better tracking ability\
\
Heuristics:\
Undefined identifier starting with uppercase letter --> class (i.e. type name) instead of an object (i.e. type instance) (lexecutor_all/snippet_36.py.orig)
\f1 \cf2 \expnd0\expndtw0\kerning0
\

\f0 \cf0 \kerning1\expnd0\expndtw0 \
When incompleter doesn't work:\
IndexError (snippet_712, snippet_645 --> poorly written code with no safeguard against list length constraints)\
\
Example with 'df': (lexecutor_all/snippet_722.py.orig)\
\
\
###################################################################################\
\
STARCODER PYTHON15B\
CODE-LLAMA PYTHON15B\
\
--> Code-LLAMA 70B (RLHF + HF-Chat) had competitive performance compared to all techniques. Has data generation capabilities. [ However, it has a high overhead of model size + it needed 13000 volunteers for the RLHF process)\
\
--> Starcoder\
      |----> Code completion mode\
			Unusable to say the least because "incompletion" fundamentally differs from "code completion"\
\
      |----> Infilling mode (asking to infill the values of missing identifiers)\
			Original snippet:\
				I could test for 10 snippets. For 4 snippets, the infiller could predict the correct type but could not generate the data.\
			Incompleter+:\
				Yet to test.\
\
	\
\
\
\
\
\
\
\
}